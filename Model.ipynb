{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '4' \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GLOBAL VARIABLES\n",
        "dataset = \"animals_2\"\n",
        "base_dir = os.path.join(\"datasets\", dataset)\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "validation_dir = os.path.join(base_dir, \"valid\")\n",
        "augmented_dir = os.path.join(base_dir, \"aug\")\n",
        "os.makedirs(augmented_dir, exist_ok=True)\n",
        "\n",
        "models_dir = os.path.join(\"models\", dataset)\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "metadata_file = os.path.join(models_dir, \"metadata.csv\")\n",
        "metrics_file = os.path.join(models_dir, \"metrics.csv\")\n",
        "\n",
        "\n",
        "# HYPERPARAMETERS\n",
        "HYPERPARAMETERS = {\n",
        "    \"model_version\": 30,\n",
        "    # Image processing\n",
        "    \"img_width\": 128,\n",
        "    \"img_height\": 128,\n",
        "    \"rescale\": 1.0 / 255,\n",
        "    \"rotation_range\": 10,\n",
        "    \"width_shift_range\": 0.2,\n",
        "    \"zoom_range\": 0.3,\n",
        "    \"horizontal_flip\": True,\n",
        "    # Training\n",
        "    \"batch_size\": 64,\n",
        "    # Model\n",
        "    \"num_classes\": 15,\n",
        "    \"learning_rate\": 0.00001,\n",
        "    # \"conv_layers\": 10,\n",
        "    # \"conv_shape\": (3, 3), \n",
        "    # \"pool_shape\": (2, 2),\n",
        "    # \"internal_neurons\": 256\n",
        "}\n",
        "\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "# USING THE HYPERPARAMETERS GENERATE A KEY (HASH)\n",
        "def generate_hash():\n",
        "    hash_input = \"\"\n",
        "    for key, value in HYPERPARAMETERS.items():\n",
        "        if isinstance(value, list):\n",
        "            value = str(value)\n",
        "        hash_input += f\"{key}:{value};\"\n",
        "    # Generate a hash\n",
        "    return hashlib.md5(hash_input.encode()).hexdigest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hash_key = generate_hash()\n",
        "\n",
        "if not os.path.exists(metadata_file):\n",
        "    cols = [\"hash_key\"]\n",
        "    cols.extend(HYPERPARAMETERS.keys())\n",
        "    metadata = pd.DataFrame(columns=cols)\n",
        "    metadata.to_csv(metadata_file, index=False)\n",
        "    \n",
        "metadata = pd.read_csv(metadata_file)\n",
        "if hash_key not in metadata[\"hash_key\"].values:\n",
        "    metadata = pd.read_csv(metadata_file)\n",
        "    new_row = {**HYPERPARAMETERS, \"hash_key\": hash_key}\n",
        "    metadata = pd.concat([metadata, pd.DataFrame([new_row])], ignore_index=True)\n",
        "    metadata.to_csv(metadata_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5bsMefaTK9A"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=HYPERPARAMETERS[\"horizontal_flip\"],\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(HYPERPARAMETERS[\"img_width\"], HYPERPARAMETERS[\"img_height\"]),\n",
        "    batch_size=HYPERPARAMETERS[\"batch_size\"],\n",
        "    class_mode=\"binary\",\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(HYPERPARAMETERS[\"img_width\"], HYPERPARAMETERS[\"img_height\"]),\n",
        "    batch_size=HYPERPARAMETERS[\"batch_size\"],\n",
        ")\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    class_mode=\"binary\",\n",
        "    target_size=(HYPERPARAMETERS[\"img_width\"], HYPERPARAMETERS[\"img_height\"]),\n",
        "    batch_size=HYPERPARAMETERS[\"batch_size\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y2957UWm1Ka",
        "outputId": "e7f4dad9-2aee-4f02-d21b-45e857ec8246"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(\n",
        "    layers.Input(\n",
        "        shape=(HYPERPARAMETERS[\"img_width\"], HYPERPARAMETERS[\"img_height\"], 3),\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    layers.Conv2D(64, kernel_size=3, activation=\"relu\", padding=\"same\")\n",
        ")\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(256, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.Conv2D(256, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(512, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.Conv2D(512, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(layers.Conv2D(512, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.Conv2D(512, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4096, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(4096, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(HYPERPARAMETERS[\"num_classes\"], activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(models_dir, hash_key, \"{epoch:02d}\", \"model.keras\"),\n",
        "        save_freq=len(train_generator) * 5,\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=0.000001,\n",
        "    ),\n",
        "    # tf.keras.callbacks.EarlyStopping(\n",
        "    #     monitor=\"val_loss\",\n",
        "    #     patience=10,\n",
        "    # ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=optimizers.Adam(learning_rate=HYPERPARAMETERS[\"learning_rate\"]),\n",
        "    metrics=[\"acc\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "histories = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=validation_generator,\n",
        ")\n",
        "\n",
        "histories.append(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "saHPzD9MXeF6",
        "outputId": "5fa7be9c-4174-4c08-d02e-8b264d57e9bd"
      },
      "outputs": [],
      "source": [
        "acc = histories[0].history['acc']\n",
        "for i in range(1, len(histories)):\n",
        "    acc = np.concatenate((acc, histories[i].history['acc']))\n",
        "\n",
        "val_acc = histories[0].history['val_acc']\n",
        "for i in range(1, len(histories)):\n",
        "    val_acc = np.concatenate((val_acc, histories[i].history['val_acc']))\n",
        "\n",
        "loss = histories[0].history['loss']\n",
        "for i in range(1, len(histories)):\n",
        "    loss = np.concatenate((loss, histories[i].history['loss']))\n",
        "\n",
        "val_loss = histories[0].history['val_loss']\n",
        "for i in range(1, len(histories)):\n",
        "    val_loss = np.concatenate((val_loss, histories[i].history['val_loss']))\n",
        "\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs_range, acc, \"bo\", label=\"train accuracy\")\n",
        "plt.plot(epochs_range, val_acc, \"ro\", label=\"validation accuracy\")\n",
        "plt.title(\"train acc\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs_range, loss, \"bo\", label=\"training loss\")\n",
        "plt.plot(epochs_range, val_loss, \"ro\", label=\"validation loss\")\n",
        "plt.title(\"train loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSHeXVn246UW",
        "outputId": "8db86baf-441a-48f1-8637-21a8de5a0032"
      },
      "outputs": [],
      "source": [
        "test_generator.reset()\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(\"\\ntest acc :\\n\", test_acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
